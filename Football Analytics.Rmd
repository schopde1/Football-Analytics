---
title: "Football Analytics Using Deep Learning"
author: "Sylvia Chopde, Thanusha Reddy, Parimal Dhasmana, Suhasini Masti"
date: "`r Sys.Date()`"
output: html_document
---


## Team members

Suhasini Masti

Sylvia Chopde

Parimal Dhasmana

Thanusha Reddy Pappu 


## Business Context 

Data-driven decision making is a vital aspect of virtually all business, and the sports industry is no exception. Over the past two decades, the influence of Data Analytics has been growing in every aspect of our lives: in businesses of every kind, but also in healthcare, media and sports. Until a few years ago, football was thought to be immune from this trend. Now, the early adopters in the major football leagues are thriving thanks to the competitive advantage that investments in data analytics are beginning to provide them: Liverpool, AZ Alkmaar and Brentford are just a few in the fast-growing list of successful case studies. In our view, the clubs that aren’t planning to jump on the analytics bandwagon run the risk of being left behind.

Football is played in over 200 countries (most popular sport globally). According to WorldAtlas, Football is the most popular sport with an estimated fan base of 4 billion. 

<center>
![](1.jpeg)


### Data
##### <span style="color: brown;">Primary Data - </span>
<ul>
  <li>The data was sourced from the pre-approved API https://www.football-data.org/documentation/quickstart </li>
</ul>

##### <span style="color: brown;">Secondary Data - </span>
Additional relevant data relating to in-game statistics-
<ul>
  <li> Match data from European Leagues - http://football-data.co.uk .</li>
</ul>


## Problem Statement

We will try to looks at some of the play-by-play statistics involved in a game, which would helps us evaluate a team’s performance, instead of just leveraging the actual number of "goals scored" metric from prior matches. 

We would combine some key metrics of a team like their half time scores, full time score based on whether its their home ground or away ground, team's overall offensive and defensive ratings which are updated after each game to build model predicting the outcome of future matches as to who the winner will be - Home Team or Away Team.

Leveraging in-game statistics can provide us interesting and deeper perspective rather than the goals metrics, creating an opportunity to look beyond the match result itself.


## Data summary, exploration, and discussion

We extracted our data from 2 sources in the API provided - Competition and Match. We could freely access data to 13 Competition ID's.
Based on that we retrieved all match details of the available competitions from the API. We could extract 3612 records from the API for the matches. We refereed to another secondary data source to enrich the existing primary data retrieved from the API. Based on the data extracted we are trying to perform analysis on whether the winner will be a Home Team, a Away Team or will it be a draw. The Features we have used to make this predictions are - Half Time Home Team Score, Half Time Away Team Score, Full Time Home Team Score, Full Time Away Team Score, Home Team, Away Team and Winner. The outcome is the Winner field.

Most of the Data extracted from the API was in the form of a list. So we had to un-nest the data and convert it into data frame. We performed Data Cleaning, Data Wrangling and Tidying on the data extracted. We also performed data un-nesting on columns which had data present in them as a list. Post enriching our data with secondary data we checked for Null Values and dropped those records from our data frame. 


Loading the required Libraries.
```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(caret)
library(httr)
library(tibble)
library(tidyverse)
library(magrittr)
library(purrr)
library(repurrrsive)
library(rlist)
library(glue)
library(patchwork)
library(data.table)
library(kableExtra)
library(h2o)
library(skimr)
library(recipes)
library(stringr)
library(tracerer)
library(ggthemes)
library(kableExtra)
library(dplyr)
```

Getting a list of competition ID's we have access to
```{r message=FALSE, warning=FALSE}
token = "5e5e6b1c0b0d4daa8619c1e31d8687d8"
football_api = GET("https://api.football-data.org//v2/competitions",
                   add_headers("X-Auth-Token"= token)
)
api_content = content(football_api)
competitions = api_content$competitions

id_vector = map_int(competitions, ~.$id)
name_vector = map_chr(competitions, ~.$name)

all_competitions = data.frame(
  id = id_vector, 
  name = name_vector
)

head(all_competitions, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```


Available competition
```{r message=FALSE, warning=FALSE}
avail_competition_id = c("2000", "2001", "2002", "2003", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2021","2152")

# Available competitions 
avail_competitions = all_competitions %>%
  filter(all_competitions$id %in% avail_competition_id)
head(avail_competitions, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

Retrieving all match details from the API corresponding to the list of available competitions
```{r message=FALSE, warning=FALSE}
match_content = list()

for(id in avail_competitions$id){
  url = glue("http://api.football-data.org/v2/competitions/{id}/matches")
  matches_comp = GET(url, add_headers("X-Auth-Token"= token))
  match_content = append(match_content, content(matches_comp))
}

for(id in avail_competitions$id){
  url = glue("http://api.football-data.org/v2/competitions/{id}/matches?dateFrom=2021-05-30&dateTo=2021-12-01")
  matches_comp = GET(url, add_headers("X-Auth-Token"= token))
  match_content = append(match_content, content(matches_comp))
}

all_matches = match_content[names(match_content) == "matches"]

for(id in avail_competitions$id){
  url = glue("http://api.football-data.org/v2/competitions/{id}/matches")
  matches_comp = GET(url, add_headers("X-Auth-Token"= token))
  match_content = append(match_content, content(matches_comp))
}

for(id in avail_competitions$id){
  url = glue("http://api.football-data.org/v2/competitions/{id}/matches?dateFrom=2021-05-30&dateTo=2021-12-01")
  matches_comp = GET(url, add_headers("X-Auth-Token"= token))
  match_content = append(match_content, content(matches_comp))
}

all_matches = match_content[names(match_content) == "matches"]

```

``` {r message=FALSE, warning=FALSE, error=TRUE}
#The data retrieved from the API is in the form of a list. We need to unnest it and convert it into a dataframe.

matches_df = data.frame()

for(x in 1:11){
  tbl <- as_tibble(all_matches[x])
  matches_df <- bind_rows(matches_df, unnest_wider(tbl,matches))
}

matches_df <- subset (matches_df, select = -c(id, season, referees, group))
head(matches_df, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

### Data Cleaning, Wrangling and Tidying

Un-nesting data from odds column
```{r message=FALSE, warning=FALSE}
matches_df  <- matches_df %>%
  mutate(df = map(odds, ~ .x %>% 
                    map_df(magrittr::extract,)))

matches_df  <- matches_df  %>%
  select(-odds) %>%
  unnest(df)

head(matches_df, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

Un-nesting list data for homeTeam column
```{r message=FALSE, warning=FALSE}
matches_df  <- matches_df %>%
  mutate(df = map(homeTeam, ~ .x %>% 
                    map_df(magrittr::extract, 
                    )))

matches_df  <- matches_df  %>%
  select(-homeTeam) %>%
  unnest(df)

matches_df <- subset (matches_df, select = -c(id))
matches_df <- matches_df %>% 
  dplyr::rename(
    homeTeam = name
  )

head(matches_df, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

Un-nesting list data for awayTeam column
```{r message=FALSE, warning=FALSE}
#Un-nesting list data for awayTeam column

matches_df  <- matches_df %>%
  mutate(df = map(awayTeam, ~ .x %>% 
                    map_df(magrittr::extract, 
                    )))
matches_df  <- matches_df  %>%
  select(-awayTeam) %>%
  unnest(df)

matches_df <- subset (matches_df, select = -c(id))

matches_df <- matches_df %>% 
  dplyr::rename(
    awayTeam = name
  )

head(matches_df, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

Un-nesting list data for scores column. This will yield full time and half time goals of the homeTeam and awayTeam
```{r message=FALSE, warning=FALSE}
scores = matches_df$score
winner_vector = map_chr(scores,"winner", .default = NA)

fullTimeScores = map(scores,"fullTime")
fTHome = map_int(fullTimeScores,"homeTeam", .default = NA)
fTAway = map_int(fullTimeScores,"awayTeam", .default = NA)

halfTimeScores = map(scores,"halfTime")
hTHome = map_int(halfTimeScores,"homeTeam", .default = NA)
hTAway = map_int(fullTimeScores,"awayTeam", .default = NA)


matches_df$winner = winner_vector
matches_df$fTHome = fTHome
matches_df$fTAway = fTAway
matches_df$hTHome = hTHome
matches_df$hTAway = hTAway

football_df <- subset (matches_df, select = -c(score))
football_df <- football_df[, c("hTHome", "hTAway","fTHome", "fTAway", "homeTeam", "awayTeam","winner")]

head(football_df, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

We are using secondary data to enrich the existing primary data retrieved from the API.
```{r message=FALSE, warning=FALSE}
for (j in c('2122','2021','1920','1718','1671','1516','1415','1314')){ 
  for( i in c('/E0','/E1','/E2','/E3','/EC')){
    url <- paste(c('https://football-data.co.uk/mmz4281/',paste(c(j, i, '.csv'), collapse="")), collapse="")
    sec_df <- read.csv(file = url)
    sec_df <- sec_df[, c("HTHG","HTAG","FTHG","FTAG","HomeTeam","AwayTeam","FTR")]
    setnames(sec_df, old = names(sec_df), 
            new = c("hTHome", "hTAway","fTHome","fTAway","homeTeam", "awayTeam","winner"))
    sec_df$winner <- as.character(sec_df$winner)
    sec_df$winner <- ifelse(sec_df$winner == "H","HOME_TEAM",sec_df$winner)
    sec_df$winner <- ifelse(sec_df$winner == "A","AWAY_TEAM",sec_df$winner)
    sec_df$winner <- ifelse(sec_df$winner == "D","DRAW",sec_df$winner)
    football_df <- rbind(football_df, sec_df) 
  }
}

head(football_df, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

Check and remove any NULL values from the data.
```{r message=FALSE, warning=FALSE}
#Check for any NULL values
colSums(is.na(football_df))

#Drop null valuess
football_df <- drop_na(football_df)
```

### The Data set has the following number of rows
```{r message=FALSE, warning=FALSE}
nrow(football_df)
```


Assessing the winner based on the outcome of the match
0: means match ended in a Draw
1: Home team Won
2: Away team Won
```{r message=FALSE, warning=FALSE}
football_df$winner <- ifelse(football_df$winner == "DRAW",0,football_df$winner)
football_df$winner <- ifelse(football_df$winner == "HOME_TEAM",1,football_df$winner)
football_df$winner <- ifelse(football_df$winner == "AWAY_TEAM",2,football_df$winner)
football_df$winner <- as.factor(football_df$winner)

# The final dataset after data cleaning, wrangling and tidying. 
head(football_df, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

## Data Visualization

1) A - Top 10 Home Team Winners
```{r message=FALSE, warning=FALSE}
count_homewins =subset(football_df, winner==1) %>% count(homeTeam)
count_homewins <- count_homewins[with(count_homewins,order(-n)),]
count_homewins <- count_homewins[1:10,]

ggplot(data = count_homewins, aes(x = reorder(homeTeam, -n), y = n, fill = homeTeam)) +
  xlab("Team Name") +
  ylab("wins")+ 
  labs(title = "Top 10 Home Team Winners ") + 
  geom_bar(stat = "identity", position = 'dodge')+
  theme_gdocs()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.6))+
  geom_text(aes(label = n), vjust = 1.5, colour = "black")+
  theme(legend.position="none")

```

B - Top 10 Home Team Winners
```{r message=FALSE, warning=FALSE}
count_awaywins =subset(football_df, winner==2) %>% count(awayTeam )
count_awaywins <- count_awaywins[with(count_awaywins,order(-n)),]
count_awaywins <- count_awaywins[1:10,]

ggplot(data = count_awaywins, aes(x = reorder(awayTeam, -n), y = n, fill = awayTeam)) +
  xlab("Team Name") +
  ylab("Wins")+ 
  labs(title = "Top 10 Away Team Winners ") + 
  geom_bar(stat = "identity", position = 'dodge')+
  theme_gdocs()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))+
  geom_text(aes(label = n), vjust = 1.5, colour = "black")+
  theme(legend.position="none")
```

2) Home Win / Draw / Away Win
```{r message=FALSE, warning=FALSE}
ggplot(football_df, aes(x=winner, fill=as.factor(winner) )) + 
  geom_bar( ) +
  scale_fill_hue(c("red", "green", "blue")) +
  geom_text( stat='count', aes(label=..count..), vjust= 2, position = position_dodge(.9) ) +
  theme(legend.position="topright")
```

3) Top 3 home winning teams: matches draw, won and lost
```{r message=FALSE, warning=FALSE}
count_homewins_top3 <- count_homewins[1:3,]
count_homewins_top3 <- count_homewins_top3[, c('homeTeam')]
three_team_df <- football_df[, c('homeTeam', 'winner')] %>% 
  filter(grepl('Man City|Liverpool|Plymouth', homeTeam))%>% 
  group_by(homeTeam)

ggplot(three_team_df, aes(homeTeam)) + 
  geom_bar(aes(fill = winner), position="dodge")+
  theme_gdocs()+
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5))+
  geom_text( stat='count', aes(fill = winner, label=..count..), vjust= 2, position = position_dodge(.9) )
```

### Split, Organize and Skim the Data

Split the dataset into train (70%) and test (30%)
```{r message=FALSE, warning=FALSE}
intrain <- createDataPartition(y = football_df$winner,
                               p = 0.7,
                               list = FALSE)

application_train <- football_df[intrain,]
application_test <- football_df[-intrain,]
application_test <- application_test %>%
  select(-winner)

```

Below is the train data
```{r message=FALSE, warning=FALSE}
head(application_train, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

Below is the test data
```{r message=FALSE, warning=FALSE}
head(application_test, n = 1000) %>% knitr::kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive")) %>% scroll_box(width="100%",height="300px")
```

Organize the data
```{r message=FALSE, warning=FALSE}
x_train_tbl <- application_train %>% 
  select(-winner)
y_train_tbl <- application_train %>% 
  select(winner)

x_test_tbl <- application_test
#Use skim for data inspection:

x_train_tbl_skim = partition(skim(x_train_tbl))
names(x_train_tbl_skim)

# Data Wrangling for ML

string_2_factor_names <- x_train_tbl_skim$character$skim_variable
string_2_factor_names


unique_numeric_values_tbl <- x_train_tbl %>%
  select(x_train_tbl_skim$numeric$skim_variable) %>%
  map_df(~ unique(.) %>% length()) %>%
  gather() %>%
  arrange(value) %>%
  mutate(key = as_factor(key))
unique_numeric_values_tbl

factor_limit <- 15
num_2_factor_names <- unique_numeric_values_tbl %>%
  filter(value < factor_limit) %>%
  arrange(desc(value)) %>%
  pull(key) %>% # pull out a single variable as a vector
  as.character()
num_2_factor_names
```

Recipes for ML Data Transformation
```{r message=FALSE, warning=FALSE}
rec_obj <- recipe(~ ., data = x_train_tbl) %>%
  step_string2factor(all_of(string_2_factor_names)) %>%
  step_num2factor(all_of(num_2_factor_names),
                  levels=str_c(0:330),
                  transform = function(x) x + 1) %>%
  step_impute_mean(all_numeric()) %>% # missing values in numeric columns
  step_impute_mode(all_nominal()) %>% # missing values in factor columns
  prep(training = x_train_tbl)

rec_obj

#Start baking:

x_train_processed_tbl <- bake(rec_obj, x_train_tbl)
x_test_processed_tbl <- bake(rec_obj, x_test_tbl)

#Transform the outcome variable (y):


rec_obj_for_y <- recipe(~ ., data = y_train_tbl) %>%
  prep(stringsAsFactors = FALSE)
y_train_processed_tbl <- bake(rec_obj_for_y, y_train_tbl)
```

## We will use H2O for deep learning

H2O supports the most widely used statistical & machine learning algorithms including gradient boosted machines, generalized linear models, deep learning and more. H2O also has an industry leading AutoML functionality that automatically runs through all the algorithms and their hyperparameters to produce a leaderboard of the best models. 
```{r message=FALSE, warning=FALSE}
library(h2o)
h2o.init(nthreads = -1)

h2o.clusterInfo()


data_h2o <- as.h2o(
  bind_cols(y_train_processed_tbl, x_train_processed_tbl),
  destination_frame= "train.hex") 

new_data_h2o <- as.h2o(
  x_test_processed_tbl,
  destination_frame= "test.hex" #destination_frame is optional
)

data_h2o_no_destination <- as.h2o(
  bind_cols(y_train_processed_tbl, x_train_processed_tbl)
)
```

Splitting the training data unto 3 subsets
```{r message=FALSE, warning=FALSE}
splits <- h2o.splitFrame(data = data_h2o,
                         ratios = c(0.7, 0.15), # 70/15/15 split
                         seed = 1234)
train_h2o <- splits[[1]] # from training data
valid_h2o <- splits[[2]] # from training data
test_h2o <- splits[[3]]  # from training data
```

## Deep Learning Model 1
### Basic deeplearning model without any tuning
```{r message=FALSE, warning=FALSE}
y <- "winner" # column name for outcome
x <- colnames(select(football_df,-c('winner','homeTeam','awayTeam','fTHome','fTAway')))

m1 <- h2o.deeplearning(
  model_id = "dl_model_first",
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o, 
  epochs = 100 
)

summary(m1)
```

## Deep Learning Model 2 with some serious tuning

Here we tune our model by adding hidden layers,epochs and learning rate for the model to learn better about the data for a more accurate prediction
```{r message=FALSE, warning=FALSE}
m2 <- h2o.deeplearning(
  model_id="dl_model_tuned",
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  overwrite_with_best_model = F, ## Return the final model after 100 epochs,
  ## even if not the best
  hidden = c(150,150,150), ## more hidden layers -> more complex interactions
  epochs = 100, 
  score_validation_samples = 10000, ## downsample validation set for faster scoring
  score_duty_cycle = 0.025, ## don't score more than 2.5% of the wall time
  adaptive_rate = F, ## manually tuned learning rate
  rate = 0.01,
  rate_annealing = 2e-6,
  momentum_start = 0.2, ## manually tuned momentum
  momentum_stable = 0.4,
  momentum_ramp = 1e7,
  l1 = 1e-5, ## add some L1/L2 regularization
  l2 = 1e-5,
  max_w2 = 10 ## helps stability for Rectifier
)

summary(m2)
```

## Hyper-parameter tuning w/grid search

Hyperparameters tuning is crucial as they control the overall behavior of a machine learning model.A hyperparameter is a parameter whose value is set before the learning process begins.H2O supports two types of grid search – traditional (or “cartesian”) grid search and random grid search.Random grid search chooses the hyperparameter sample combinations randomly from grid space. Because of this reason, there is no guarantee that we will find the best result like exhaustive Grid Search. But, this search can be extremely effective in practice as computational time is very less.
```{r message=FALSE, warning=FALSE}
hyper_params <- list(
  hidden = list( c(50,50,50), c(100,100) ),
  input_dropout_ratio = c(0, 0.05),
  rate = c(0.01, 0.02),
  rate_annealing = c(1e-8, 1e-7, 1e-6)
)

grid <- h2o.grid(
  algorithm="deeplearning",
  grid_id="dl_grid",
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  epochs = 100,
  stopping_metric = "misclassification",
  stopping_tolerance = 1e-2, 
  stopping_rounds = 2,
  score_validation_samples = 10000, ## downsample validation set for faster scoring
  score_duty_cycle = 0.025, ## don't score more than 2.5% of the wall time
  adaptive_rate = F, #manually tuned learning rate
  momentum_start = 0.5, #manually tuned momentum
  momentum_stable = 0.9,
  momentum_ramp = 1e7,
  l1 = 1e-5,
  l2 = 1e-5,
  activation = c("Rectifier"),
  max_w2 = 10, #can help improve stability for Rectifier
  hyper_params = hyper_params
)

grid <- h2o.getGrid("dl_grid", sort_by="logloss", decreasing=FALSE)
dl_grid_summary_table <- grid@summary_table
dl_grid_summary_table
```

To find best model in the grid
```{r message=FALSE, warning=FALSE}
dl_grid_best_model <- h2o.getModel(dl_grid_summary_table$model_ids[1])
summary(dl_grid_best_model)
```

To find parameters used in the best model
```{r message=FALSE, warning=FALSE}
dl_grid_best_model_params <- dl_grid_best_model@allparameters
dl_grid_best_model_params
```

Auto Ml in H2O
```{r message=FALSE, warning=FALSE}
automl_models_h2o <- h2o.automl(
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs = 900 
)

automl_leaderboard <- automl_models_h2o@leaderboard
automl_leaderboard

automl_leader <- automl_models_h2o@leader

performance_h2o <- h2o.performance(automl_leader, newdata = test_h2o)
performance_h2o %>%
  h2o.confusionMatrix()
```

Close H2O
```{r message=FALSE, warning=FALSE}

```

```{r message=FALSE, warning=FALSE}
h2o.shutdown(prompt = F)
```

## Conclusion


The results from the Auto ML were superior than the simple ML model with hyperparameter tuning with grid search.
From the Auto ML confusion matrix, the total error across each class is 0.41. The RMSE is also very good at 0.56. We also observed Auto ML classified more cases correctly that the other 3 models.

As per the variable importance generated , the predictors that made the impact were: hTAway, hTHome

We used the Classification accuracy, confusion matrix(precision and Recall) and RMSE for evaluation.